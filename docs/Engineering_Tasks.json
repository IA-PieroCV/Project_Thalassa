{
  "projectName": "Project Thalassa",
  "stories": [
    {
      "story_title": "Partner provides sequence data via a shared folder",
      "epic_name": "Data Ingestion and Processing",
      "tasks": [
        {
          "title": "BE: Create FastAPI endpoint for `fastq` file uploads",
          "body": "Implement a new POST endpoint in the FastAPI application that accepts `multipart/form-data`. This endpoint will handle the streaming and saving of large `.fastq` files directly to the server's local filesystem as specified in `Technical_Architecture.md`.",
          "labels": ["backend", "feature", "api", "fastapi"]
        },
        {
          "title": "BE: Secure upload endpoint with shared Bearer Token authentication",
          "body": "Apply a security dependency to the file upload endpoint. This dependency must validate a shared Bearer Token provided in the 'Authorization' header. The token should be read from an environment variable for security.",
          "labels": ["backend", "feature", "security", "auth"]
        },
        {
          "title": "DOCS: Create partner guide for uploading data via API",
          "body": "Write a simple markdown document for the partner explaining how to use a tool like `cURL` to upload their files. The guide must include the endpoint URL, an example of the `Authorization` header, and the mandatory file naming convention: `PartnerID_CageID_YYYY-MM-DD_SampleID.fastq`.",
          "labels": ["documentation", "partner-facing"]
        },
        {
          "title": "TEST: Write integration test for the authenticated file upload",
          "body": "Create a Pytest integration test that uses an HTTP client to post a sample file to the upload endpoint with a valid token. The test must assert a `200 OK` response and verify that the file was correctly saved to the designated directory on the filesystem.",
          "labels": ["testing", "integration-test"]
        }
      ]
    },
    {
      "story_title": "Analyst generates risk score from data",
      "epic_name": "Data Ingestion and Processing",
      "tasks": [
        {
          "title": "BE: Implement logic in analysis script to read `.fastq` files from local directory",
          "body": "The analysis script needs a function that can scan a specific directory on the OCI VPS filesystem (e.g., `/data/uploads`) and return a list of `.fastq` files to be processed.",
          "labels": ["backend", "feature", "data-science"]
        },
        {
          "title": "BE: Implement filename parser to extract `PartnerID` and `CageID`",
          "body": "Create a robust function that takes a filename as input and parses it based on the `PartnerID_CageID_YYYY-MM-DD_SampleID.fastq` convention. It must correctly extract the `CageID` and handle potential naming errors gracefully.",
          "labels": ["backend", "feature", "parser"]
        },
        {
          "title": "BE: Integrate core SRS risk analysis model into the Python script",
          "body": "Create a wrapper or main execution function in the script. This function will orchestrate the process: for each input file, it will call the core bioinformatics/AI model and capture the numerical risk score output.",
          "labels": ["backend", "feature", "data-science"]
        },
        {
          "title": "BE: Implement `results.json` output generation",
          "body": "After processing all files, the script must aggregate the results and write them to the `results.json` file in the application's root directory. The output must strictly follow the format: `[{ \"cageId\": \"...\", \"srsRiskScore\": ..., \"lastUpdated\": \"...\" }]`. The file should be completely overwritten on each run.",
          "labels": ["backend", "feature", "data-format"]
        },
        {
          "title": "TEST: Write unit tests for filename parser and JSON output formatter",
          "body": "Create dedicated unit tests using Pytest for the filename parsing logic and the JSON generation function. Include tests for valid names, names with errors, and edge cases.",
          "labels": ["testing", "unit-test"]
        },
        {
          "title": "DEV-OPS: Create single Dockerfile for the combined FastAPI & analysis application",
          "body": "Create one `Dockerfile` that sets up a Python environment, installs dependencies from `requirements.txt` (including FastAPI, Uvicorn, and any data science libraries), copies all application and script files, and defines the `CMD` to run the Uvicorn server. This single container will be deployed to the OCI VPS.",
          "labels": ["devops", "docker", "deployment"]
        }
      ]
    },
    {
      "story_title": "Partner accesses dashboard with a password",
      "epic_name": "Risk Reporting & Alerting",
      "tasks": [
        {
          "title": "BE: Set up basic FastAPI application skeleton",
          "body": "Initialize the main `main.py` for the FastAPI application. Set up the basic app instance and a simple `/health` check endpoint to confirm it's running.",
          "labels": ["backend", "setup", "api"]
        },
        {
          "title": "FE: Create placeholder `dashboard.html` file",
          "body": "Create a static `dashboard.html` file within a `/templates` directory. It should contain basic HTML boilerplate and a title like 'Thalassa Risk Dashboard'. This will be used to verify the serving mechanism.",
          "labels": ["frontend", "setup", "ui"]
        },
        {
          "title": "BE: Create authenticated FastAPI endpoint to serve the dashboard HTML",
          "body": "Implement a GET endpoint (e.g., at `/`) that is protected by the same shared Bearer Token mechanism. Upon successful authentication, it should use Jinja2Templates to render and return the `dashboard.html` file.",
          "labels": ["backend", "feature", "api", "auth"]
        },
        {
          "title": "DOCS: Securely document and share the Bearer Token with the partner",
          "body": "Create an internal document detailing the shared Bearer Token. Establish a secure, one-time method for communicating this token to the partner's primary contact.",
          "labels": ["documentation", "security"]
        }
      ]
    },
    {
      "story_title": "Partner views risk scores on the dashboard",
      "epic_name": "Risk Reporting & Alerting",
      "tasks": [
        {
          "title": "BE: Implement logic in dashboard endpoint to read and parse `results.json`",
          "body": "Enhance the dashboard GET endpoint. Before rendering the template, the function must read the `results.json` file from the filesystem, parse it into a Python object, and pass it to the template context. It must handle cases where the file doesn't exist yet (e.g., by passing an empty list).",
          "labels": ["backend", "feature", "api"]
        },
        {
          "title": "FE: Update `dashboard.html` to dynamically render risk scores with Jinja2",
          "body": "Modify the `dashboard.html` template. Add a Jinja2 for-loop to iterate over the results data passed from the backend. For each item, render a list item or table row displaying the `cageId` and `srsRiskScore`.",
          "labels": ["frontend", "feature", "ui"]
        },
        {
          "title": "TEST: Write integration test for dashboard data rendering",
          "body": "Create an integration test that pre-creates a mock `results.json` file, calls the dashboard endpoint with a valid token, and asserts that the returned HTML body contains the specific data from the mock file.",
          "labels": ["testing", "integration-test"]
        }
      ]
    },
    {
      "story_title": "Analyst manually alerts partner of critical risk",
      "epic_name": "Risk Reporting & Alerting",
      "tasks": [
        {
          "title": "BE: Add console logging for critical risk scores in analysis script",
          "body": "In the analysis script, after a score is generated, compare it against a hardcoded or environment-variable-defined threshold (e.g., 0.80). If the score exceeds the threshold, print a highly visible warning to the console (stdout) to alert the running analyst.",
          "labels": ["backend", "feature", "logging"]
        },
        {
          "title": "DOCS: Create pre-defined email alert template",
          "body": "Create a file named `critical_alert_template.txt` in the repository. The file will contain the standard text for the manual email alert, with placeholders like `[Cage ID]`, `[Risk Score]`, and `[Date of Analysis]` for the analyst to fill in.",
          "labels": ["documentation"]
        }
      ]
    }
  ]
}
